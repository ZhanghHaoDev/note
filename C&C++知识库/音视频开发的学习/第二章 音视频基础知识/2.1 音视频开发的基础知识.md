# 音视频开发的基础知识

# 视频开发

## 1. 视频开发 note

1. 视频的定义和基本概念：视频是一系列静止图像（帧）按照一定的时间顺序连续播放而形成的动态画面。每秒钟播放的帧数称为帧率，通常以fps（frames per second）为单位。视频的基本属性包括分辨率、帧率、颜色深度等。
2. 视频帧和帧率：视频帧是构成视频的基本单位，每一帧都是一幅静止的图像。帧率（Frame Rate）是指每秒钟播放的帧数，常见的帧率有24fps、30fps、60fps等。帧率越高，视频越流畅，但同时也会增加存储和传输的压力。
3. 分辨率和像素：分辨率是指视频图像的清晰度，通常用水平像素数和垂直像素数表示，如1920x1080（即1080p）。像素是构成图像的最小单位，每个像素包含颜色信息。分辨率越高，图像越清晰，但也会占用更多的存储空间和带宽。视频的分辨率并不一定是固定的。虽然常见的视频分辨率有标准的长宽比（如 1920x1080 的 16:9 比例），但在实际应用中，视频的分辨率可以根据需求进行调整
4. 1080P当中的P表示什么意思？
1080P中的"P"代表逐行扫描（Progressive scan），这是一种视频显示格式，其中数字1080表示垂直方向有1080条水平扫描线，而"P"表示图像是逐行呈现的，不是隔行扫描（Interlaced scan）。逐行扫描可以提供更平滑、更清晰的图像，因为它在同一帧中显示所有的像素行，而隔行扫描则将一帧分成两个字段，先显示所有奇数行，然后是所有偶数行，这可能会导致观看快速运动的画面时出现轻微的闪烁或模糊。
不带"P"的1080，即1080i，表示视频是以隔行扫描的方式呈现，其中"i"代表交错式扫描（Interlaced scan）。在1080i中，虽然垂直分辨率也是1080线，但这些线是分成两个字段来显示的，每个字段包含540线，分别在不同的时间显示，这样可以在保持较高垂直分辨率的同时减少所需的带宽。
5. RGB颜色空间
RGB颜色空间是最常见的颜色表示方法之一，使用红色（Red）、绿色（Green）和蓝色（Blue）三种颜色的不同组合来表示各种颜色。每种颜色的强度通常用0到255之间的整数表示，因此一个像素可以用三个字节（24位）来表示。
6. YUV颜色空间
YUV颜色空间是一种更适合视频压缩和传输的颜色表示方法。它将颜色信息分为亮度（Y）和色度（U和V）三个分量。Y表示亮度，U和V表示色度。YUV颜色空间利用了人眼对亮度更敏感、对色度不太敏感的特点，可以更有效地压缩视频数据。
7. RGB和YUV的区别
RGB和YUV都属于颜色空间，RGB主要是蓝色，绿色，红色，YUV主要用于视频系统，Y表示亮度或者灰度，U和V表示色度或者色彩，主要的区别是如何表示颜色

## 2. 视频的编解码

1. 解码：解码是将压缩的音视频数据还原为原始的音视频数据的过程。解码器会根据编码器使用的**压缩**算法，逆向处理数据，恢复出原始的音视频信号。
2. 编码：编码是将原始的音视频数据压缩为更小的数据量的过程。编码器通过去除冗余数据和应用**压缩**算法，减少数据量，同时尽量保持音视频的质量。
3. 编码过程中压缩的参数：空间冗余，时间冗余，视觉冗余，统计冗余
4. 在实际操作过程中，可以通过调整编码器的参数来控制视频的质量和压缩比。常见的调整参数包括：比特率控制，量化参数，分辨率调整，帧率调整，音频参数调整
5. 为什么对视频编码：视频编码的主要目的是为了压缩视频数据，以便于存储和传输。未经压缩的视频数据量非常大，直接存储和传输会占用大量的存储空间和带宽资源。通过视频编码，可以大幅度减少视频文件的大小，同时尽可能保持视频的画质。具体来说，视频编码有以下几个主要目的：
    1. **减少存储空间**：压缩后的视频文件占用的存储空间更小，便于在硬盘、光盘等介质上存储。
    2. **降低传输带宽**：压缩后的视频数据量更小，便于通过网络进行传输，减少带宽占用，提高传输效率。
    3. **提高传输速度**：压缩后的视频文件更小，传输速度更快，减少了视频加载和缓冲的时间。
    4. **适应不同设备**：通过不同的编码格式和压缩率，可以生成适合不同设备和网络环境的视频文件，提供更好的用户体验。

# 音频开发 

## 1. 音频开发 note

1. 声音的物理性质
   - **振动**：声音是由物体的振动产生的。振动通过空气或其他介质传播，形成声波。
   - **波形**：声波的形状称为波形。不同的波形对应不同的声音特性，如纯音、噪音等。
   - **频率**：声波每秒钟振动的次数称为频率，单位是赫兹（Hz）。频率决定了声音的音高，高频声音听起来尖锐，低频声音听起来低沉。
   - **振幅**：声波的最大偏离值称为振幅，决定了声音的响度。振幅越大，声音越响。

2. 数字音频
   - **数字音频的基本概念**：数字音频是将连续的模拟声音信号转换为离散的数字信号。通过采样和量化，将声音信号表示为一系列数字值。
   - **PCM脉冲编码调制**：PCM（Pulse Code Modulation）是最常见的数字音频编码方法。它通过定期采样模拟信号，并将每个样本量化为数字值。
   - **采样频率**：采样频率是指每秒钟对模拟信号进行采样的次数，单位是赫兹（Hz）。常见的采样频率有44.1kHz（CD音质）、48kHz（专业音频）等。采样频率越高，数字音频的质量越好。
   - **采样量化**：采样量化是将每个采样点的振幅值转换为离散的数字值。量化的精度由比特深度（Bit Depth）决定，常见的比特深度有16位、24位等。比特深度越高，音频的动态范围越大。

3. 采样频率：每秒钟对模拟信号进行采样的次数，决定了音频的频率范围和质量。
4. 采样精度：每个采样点的量化精度，通常用比特深度表示，决定了音频的动态范围。也叫比特深度
5. 通道数：音频信号的独立通道数，如单声道（Mono）、立体声（Stereo）、环绕声（Surround）。
6. 比特率：每秒钟传输的比特数，通常以kbps为单位，表示音频的压缩程度和质量。
7. 码率：音频数据的传输速率，通常以kbps为单位，表示音频的压缩程度和质量。
8. 帧：音频数据的基本单位，包含若干采样点。帧的长度通常是固定的。
9. 帧长：每个音频帧包含的采样点数，决定了音频数据的时间分辨率。
10. 交错模式：音频数据的存储方式，将多个通道的数据交错存储，以便于同时读取和处理。
11. 非交错模式：音频数据的存储方式，将每个通道的数据分别存储，适用于需要单独处理每个通道的场景。
12. 采样点 ：音频信号在时间上的离散表示，每个采样点对应一个时间点的振幅值。 采样点类型：
    1. **`int16_t`**：对于16位音频，通常使用16位整数类型，如`int16_t`（定义在`<cstdint>`或`<stdint.h>`头文件中）。
    2. **`int32_t`**：对于24位或32位音频，可以使用32位整数类型，如`int32_t`。
    3. **`float`**：对于浮点音频数据，可以使用`float`类型。
    4. **`double`**：对于需要更高精度的音频处理，可以使用`double`类型。
    5. **`uint8_t`**：对于8位音频，可以使用8位无符号整数类型，如`uint8_t`。
13. 采样点个数与下面的参数有关：
    + 单通道采样点个数 = 采样频率 × 音频时长
    + 多通道总采样点个数 = 采样频率 × 音频时长 × 通道数
    + 存储大小 = 采样点个数 × 比特深度
    + 采样点的个数与音频的格式无关
14. 音频重采样:音频重采样就是将音频进行重新采样得到新的采样率/采样位数/声道数。音频重采样通常用于音频格式转换、音频处理和音频播放等场景。
